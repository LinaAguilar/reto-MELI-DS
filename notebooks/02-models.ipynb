{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para el procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la ganancia de la empresa\n",
    "def calcular_ganancia(y_true, y_pred, monto):\n",
    "    \"\"\"\n",
    "    Calcula la ganancia basada en las predicciones:\n",
    "    - Falso negativo (fraude no detectado) -> pérdida del 100% del monto\n",
    "    - Transacción aprobada correctamente -> ganancia del 25% del monto\n",
    "    - Transacción denegada -> sin ganancia\n",
    "    \"\"\"\n",
    "    df_resultado = pd.DataFrame({'fraude_real': y_true, 'fraude_predicho': y_pred, 'monto': monto})\n",
    "\n",
    "    # Casos donde el fraude real es 1 pero fue predicho como 0 (Falso Negativo)\n",
    "    perdida = df_resultado[(df_resultado['fraude_real'] == 1) & (df_resultado['fraude_predicho'] == 0)]['monto'].sum()\n",
    "\n",
    "    # Casos donde se aprueba la transacción (fraude_predicho == 0), se obtiene 25% de ganancia\n",
    "    ganancia = df_resultado[df_resultado['fraude_predicho'] == 0]['monto'].sum() * 0.25\n",
    "\n",
    "    # Ganancia total\n",
    "    ganancia_total = ganancia - perdida\n",
    "\n",
    "    return ganancia_total\n",
    "\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con pesos de clase\n",
    "def train_and_evaluate_model_with_weights(model, X_train, y_train, X_test, y_test, monto_test, model_name):\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"\\n--- Evaluando modelo: {model_name} ---\")\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nReporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "    # Calcular la ganancia de la empresa\n",
    "    ganancia = calcular_ganancia(y_test, y_pred, monto_test)\n",
    "    print(f\"\\nGanancia estimada para {model_name}: {ganancia:.2f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Función para entrenar y evaluar un modelo\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, monto_test, model_name):\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    print(f\"\\n--- Evaluando modelo: {model_name} ---\")\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nReporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "    # Calcular la ganancia de la empresa\n",
    "    ganancia = calcular_ganancia(y_test, y_pred, monto_test)\n",
    "    print(f\"\\nGanancia estimada para {model_name}: {ganancia:.2f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (120000, 71)\n",
      "Forma de X_test: (30000, 71)\n",
      "Forma de y_train: (120000,)\n",
      "Forma de y_test: (30000,)\n"
     ]
    }
   ],
   "source": [
    "df_processed = pd.read_csv('../data/df_processed.csv')\n",
    "\n",
    "X = df_processed.drop(columns=['fraude','monto'])  # Todas las columnas excepto la variable objetivo y monto que se va a usar para el calculo de la ganancia\n",
    "y = df_processed['fraude']  # Variable objetivo\n",
    "monto = df_processed['monto'] #se usará solo para la ganancia\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test, monto_train, monto_test = train_test_split(\n",
    "    X, y, monto, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Verificar las formas de los conjuntos\n",
    "print(f\"Forma de X_train: {X_train.shape}\")\n",
    "print(f\"Forma de X_test: {X_test.shape}\")\n",
    "print(f\"Forma de y_train: {y_train.shape}\")\n",
    "print(f\"Forma de y_test: {y_test.shape}\")\n",
    "\n",
    "# Calcular el ratio de desbalanceo para XGBoost\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# Definir los modelos con pesos de clase\n",
    "models = {\n",
    "    \"Regresión Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubits.PC220318\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "\n",
      "--- Evaluando modelo: Regresión Logística ---\n",
      "Matriz de confusión:\n",
      "[[22184  6316]\n",
      " [  375  1125]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     28500\n",
      "           1       0.15      0.75      0.25      1500\n",
      "\n",
      "    accuracy                           0.78     30000\n",
      "   macro avg       0.57      0.76      0.56     30000\n",
      "weighted avg       0.94      0.78      0.84     30000\n",
      "\n",
      "AUC-ROC: 0.8512\n",
      "\n",
      "Ganancia estimada para Regresión Logística: 190604.58\n",
      "---------------------------------------------------\n",
      "\n",
      "--- Evaluando modelo: Random Forest ---\n",
      "Matriz de confusión:\n",
      "[[28434    66]\n",
      " [ 1262   238]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     28500\n",
      "           1       0.78      0.16      0.26      1500\n",
      "\n",
      "    accuracy                           0.96     30000\n",
      "   macro avg       0.87      0.58      0.62     30000\n",
      "weighted avg       0.95      0.96      0.94     30000\n",
      "\n",
      "AUC-ROC: 0.8743\n",
      "\n",
      "Ganancia estimada para Random Forest: 229600.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubits.PC220318\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:158: UserWarning: [11:20:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "\n",
      "--- Evaluando modelo: XGBoost ---\n",
      "Matriz de confusión:\n",
      "[[25331  3169]\n",
      " [  467  1033]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93     28500\n",
      "           1       0.25      0.69      0.36      1500\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.61      0.79      0.65     30000\n",
      "weighted avg       0.95      0.88      0.90     30000\n",
      "\n",
      "AUC-ROC: 0.8831\n",
      "\n",
      "Ganancia estimada para XGBoost: 230766.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    trained_model = train_and_evaluate_model_with_weights(model, X_train, y_train, X_test, y_test, monto_test, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con los datos balanceados mediante SMOTE + Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train_balanced: (227774, 71)\n",
      "Forma de X_test_balanced: (56944, 71)\n",
      "Forma de y_train_balanced: (227774,)\n",
      "Forma de y_test_balanced: (56944,)\n"
     ]
    }
   ],
   "source": [
    "df_processed_balanced = pd.read_csv('../data/df_processed_balanced.csv')\n",
    "\n",
    "# Separar características (X) y variable objetivo (y) del dataset balanceado\n",
    "X_balanced = df_processed_balanced.drop(columns=['fraude','monto'])\n",
    "y_balanced = df_processed_balanced['fraude']\n",
    "monto_balanced = df_processed_balanced['monto']  # Para calcular la ganancia\n",
    "\n",
    "# Dividir los datos balanceados en conjuntos de entrenamiento y prueba\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced, monto_train, monto_test = train_test_split(\n",
    "    X_balanced, y_balanced, monto_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# Verificar las formas de los conjuntos\n",
    "print(f\"Forma de X_train_balanced: {X_train_balanced.shape}\")\n",
    "print(f\"Forma de X_test_balanced: {X_test_balanced.shape}\")\n",
    "print(f\"Forma de y_train_balanced: {y_train_balanced.shape}\")\n",
    "print(f\"Forma de y_test_balanced: {y_test_balanced.shape}\")\n",
    "\n",
    "# Definir los modelos\n",
    "models = {\n",
    "    \"Regresión Logística\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubits.PC220318\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando modelo: Regresión Logística ---\n",
      "Matriz de confusión:\n",
      "[[24602  3870]\n",
      " [ 4966 23506]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85     28472\n",
      "           1       0.86      0.83      0.84     28472\n",
      "\n",
      "    accuracy                           0.84     56944\n",
      "   macro avg       0.85      0.84      0.84     56944\n",
      "weighted avg       0.85      0.84      0.84     56944\n",
      "\n",
      "AUC-ROC: 0.9248\n",
      "\n",
      "Ganancia estimada para Regresión Logística: 75016.18\n",
      "\n",
      "--- Evaluando modelo: Random Forest ---\n",
      "Matriz de confusión:\n",
      "[[27574   898]\n",
      " [ 1171 27301]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     28472\n",
      "           1       0.97      0.96      0.96     28472\n",
      "\n",
      "    accuracy                           0.96     56944\n",
      "   macro avg       0.96      0.96      0.96     56944\n",
      "weighted avg       0.96      0.96      0.96     56944\n",
      "\n",
      "AUC-ROC: 0.9934\n",
      "\n",
      "Ganancia estimada para Random Forest: 231841.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubits.PC220318\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:158: UserWarning: [11:21:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando modelo: XGBoost ---\n",
      "Matriz de confusión:\n",
      "[[27758   714]\n",
      " [ 2054 26418]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     28472\n",
      "           1       0.97      0.93      0.95     28472\n",
      "\n",
      "    accuracy                           0.95     56944\n",
      "   macro avg       0.95      0.95      0.95     56944\n",
      "weighted avg       0.95      0.95      0.95     56944\n",
      "\n",
      "AUC-ROC: 0.9869\n",
      "\n",
      "Ganancia estimada para XGBoost: 199708.09\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar cada modelo con el conjunto balanceado\n",
    "for name, model in models.items():\n",
    "    trained_model = train_and_evaluate_model(model, X_train_balanced, y_train_balanced, X_test_balanced, y_test_balanced, monto_test, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
